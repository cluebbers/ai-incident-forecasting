{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aacf9a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import logging\n",
    "from data_loaders import load_and_merge\n",
    "from forecast_helpers import ForecastConfig\n",
    "from forecast_eval import backtest_forecast, naive_baseline_forecast\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Suppress warnings and pandas settings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.options.mode.chained_assignment = None\n",
    "pd.set_option(\"display.precision\", 2)\n",
    "\n",
    "# Configure logging - remove duplicate handlers and prevent propagation\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(message)s\", force=True)\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.handlers.clear()  # Clear any existing handlers\n",
    "console_handler = logging.StreamHandler()\n",
    "console_handler.setLevel(logging.INFO)\n",
    "logger.addHandler(console_handler)\n",
    "logger.propagate = False  # Prevent propagation to root logger\n",
    "\n",
    "# Load data and define evaluation period\n",
    "df = load_and_merge()\n",
    "test_years = [2022, 2023, 2024]\n",
    "\n",
    "# Model configuration\n",
    "base_config = ForecastConfig(\n",
    "    MAX_KNOTS_TOTAL=6,\n",
    "    MAX_KNOTS_SHARES=4,\n",
    "    ALPHA_TOTAL=0.005,\n",
    "    TAU_YEARS=5.0,\n",
    "    W_HIST_MAX=0.4,\n",
    "    W_UNIF_MAX=0.2,\n",
    "    MOM_TILT_MAX=0.7,\n",
    "    MOM_TAU=3,\n",
    "    RECENT_WIN=7,\n",
    "    CAT_BOOST_SURGE=7,\n",
    "    GROWTH_FLOOR_FRAC=0.07,\n",
    "    SHARE_KAPPA=35,\n",
    "    # from calibration_analysis.ipynb\n",
    "    B_SIM=5000,                    # Increased for stability\n",
    "    CONFIDENCE_LEVEL=0.90,         \n",
    "    BOOTSTRAP_ITERS=500,           \n",
    "    MIN_PI_WIDTH=0.2,              \n",
    "    GROWTH_UNCERTAINTY_FACTOR=1,  # Calibrated value 0.686,\n",
    "    YTD_YEAR=2025,\n",
    "    MONOTONE_TOTALS=False,\n",
    "    NO_DIP_FIRST_YEAR=False,\n",
    "    NONDECREASING_CATEGORIES=False,\n",
    "    ASSIMILATE_YTD=False # True for production\n",
    ")\n",
    "\n",
    "# Log configuration - modify the logging section\n",
    "logger.info(\"\\nRunning backtest with config:\")\n",
    "for k, v in sorted(base_config.__dict__.items()):\n",
    "    if not k.startswith(\"_\"):  # Only log public attributes\n",
    "        logger.info(f\"- {k}: {v}\")\n",
    "\n",
    "# Run models\n",
    "model_results = backtest_forecast(df, \"date\", \"Risk Domain\", test_years, base_config)\n",
    "baseline_results = naive_baseline_forecast(df, \"date\", test_years)\n",
    "\n",
    "\n",
    "def summarize_results(results, model_name):\n",
    "    \"\"\"Create DataFrame summarizing model results.\n",
    "\n",
    "    Args:\n",
    "        results: List of BacktestResult objects\n",
    "        model_name: Name of the model for identification\n",
    "\n",
    "    Returns:\n",
    "        DataFrame with performance metrics\n",
    "    \"\"\"\n",
    "    return pd.DataFrame(\n",
    "        {\n",
    "            \"Year\": [r.year for r in results],\n",
    "            \"Actual\": [r.actual for r in results],\n",
    "            \"Predicted\": [r.predicted for r in results],\n",
    "            \"MAE\": [r.mae for r in results],\n",
    "            \"MAPE\": [r.mape for r in results],\n",
    "            \"RMSE\": [r.rmse for r in results],\n",
    "            \"Model\": model_name,\n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "# Combine results\n",
    "results_df = pd.concat(\n",
    "    [\n",
    "        summarize_results(model_results, \"Main Model\"),\n",
    "        summarize_results(baseline_results, \"Baseline\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Visualization\n",
    "plt.figure(figsize=(10, 6))\n",
    "for model in [\"Main Model\", \"Baseline\"]:\n",
    "    mask = results_df[\"Model\"] == model\n",
    "    plt.plot(\n",
    "        results_df[mask][\"Year\"],\n",
    "        results_df[mask][\"Predicted\"],\n",
    "        \"o-\",\n",
    "        label=f\"{model} prediction\",\n",
    "    )\n",
    "plt.plot(\n",
    "    results_df[\"Year\"].unique(),\n",
    "    results_df[results_df[\"Model\"] == \"Main Model\"][\"Actual\"],\n",
    "    \"k--\",\n",
    "    label=\"Actual\",\n",
    ")\n",
    "plt.legend()\n",
    "plt.title(\"Forecast vs Actual: Model Comparison\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# Performance summary\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"MODEL PERFORMANCE SUMMARY\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(\"\\nAverage Error Metrics:\")\n",
    "print(results_df.groupby(\"Model\")[[\"MAE\", \"MAPE\", \"RMSE\"]].mean())\n",
    "\n",
    "print(\"\\nDetailed Results by Year:\")\n",
    "print(results_df.sort_values([\"Year\", \"Model\"]))\n",
    "\n",
    "# Main model error analysis\n",
    "model_metrics = results_df[results_df[\"Model\"] == \"Main Model\"][\n",
    "    [\"Year\", \"Actual\", \"Predicted\"]\n",
    "]\n",
    "model_metrics[\"Error %\"] = (\n",
    "    (model_metrics[\"Predicted\"] - model_metrics[\"Actual\"])\n",
    "    / model_metrics[\"Actual\"]\n",
    "    * 100\n",
    ")\n",
    "print(\"\\nMain Model Yearly Errors:\")\n",
    "print(model_metrics.to_string(index=False))\n",
    "\n",
    "\n",
    "def calculate_adaptive_metrics(results_df):\n",
    "    \"\"\"Calculate growth-adjusted performance metrics.\n",
    "\n",
    "    Args:\n",
    "        results_df: DataFrame containing model results\n",
    "\n",
    "    Returns:\n",
    "        float: Weighted error accounting for growth rates\n",
    "    \"\"\"\n",
    "    main_model = results_df[results_df[\"Model\"] == \"Main Model\"].copy()\n",
    "    main_model[\"Growth_Rate\"] = main_model[\"Actual\"].pct_change()\n",
    "    main_model[\"Weighted_Error\"] = main_model[\"MAPE\"] * (1 + main_model[\"Growth_Rate\"])\n",
    "    return main_model[\"Weighted_Error\"].mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "timaeus",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
